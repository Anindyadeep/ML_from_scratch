{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION TESTS WITH SKLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data for the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_features = 10\n",
    "X, y = make_regression(n_samples=600, n_features=n_features, noise=20, random_state=4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Simple Regression class of ours and Sklearns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA LOSS OF OUR MODEL:  [[281.13983579]]\n",
      "TEST DATA LOSS OF OUR SKLEARN's:  [[280.79610222]]\n"
     ]
    }
   ],
   "source": [
    "import Regression as r \n",
    "import sklearn.linear_model as lm \n",
    "\n",
    "# our method\n",
    "regressor_r = r.LinearRegression(X_train, y_train)\n",
    "regressor_r.train(epochs=200, learning_rate=0.03)\n",
    "\n",
    "# sklearn's method\n",
    "regressor_lm = lm.LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(\"TEST DATA LOSS OF OUR MODEL: \", regressor_r.loss(regressor_r.predict(X_test), y_test))\n",
    "print(\"TEST DATA LOSS OF OUR SKLEARN's: \", regressor_r.loss(regressor_lm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Polynomial Regression class of ours and Sklearns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# our method\n",
    "pol_r = r.PolynomialRegression(X_train, y_train, 2)\n",
    "pol_r.train(epochs=300, learning_rate=0.03)\n",
    "\n",
    "# sklearn's method\n",
    "pl_lm = make_pipeline(PolynomialFeatures(2), lm.LinearRegression())\n",
    "pl_lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA LOSS OF OUR MODEL:  [[291.88643893]]\n",
      "TEST DATA LOSS OF OUR SKLEARN's:  [[291.48653518]]\n"
     ]
    }
   ],
   "source": [
    "preds_pol_r = pol_r.predict(X_test)\n",
    "preds_pol_lm = pl_lm.predict(X_test)\n",
    "\n",
    "print(\"TEST DATA LOSS OF OUR MODEL: \", pol_r.loss(preds_pol_r, y_test))\n",
    "print(\"TEST DATA LOSS OF OUR SKLEARN's: \", pol_r.loss(preds_pol_lm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Ridge Regression class of ours and Sklearns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA LOSS OF OUR MODEL:  [[281.98112886]]\n",
      "TEST DATA LOSS OF OUR SKLEARN's:  [[280.79961173]]\n"
     ]
    }
   ],
   "source": [
    "# our method\n",
    "ridge_r = r.RidgeRegression(X_train, y_train, 0.0003)\n",
    "ridge_r.train(epochs=200, learning_rate=0.03)\n",
    "\n",
    "# sklearn's method\n",
    "ridge_lm = lm.Ridge(alpha=0.0003).fit(X_train, y_train)\n",
    "\n",
    "print(\"TEST DATA LOSS OF OUR MODEL: \", ridge_r.loss(ridge_r.predict(X_test), y_test))\n",
    "print(\"TEST DATA LOSS OF OUR SKLEARN's: \", ridge_r.loss(ridge_lm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Ridge Regression class of ours and Sklearns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA LOSS OF OUR MODEL:  [[281.15060897]]\n",
      "TEST DATA LOSS OF OUR SKLEARN's:  [[280.8193745]]\n"
     ]
    }
   ],
   "source": [
    "# our method\n",
    "lasso_r = r.LassoRegression(X_train, y_train, 0.0003)\n",
    "lasso_r.train(epochs=200, learning_rate=0.03)\n",
    "\n",
    "# sklearn's method\n",
    "lasso_lm = lm.Lasso(alpha=0.0003).fit(X_train, y_train)\n",
    "\n",
    "print(\"TEST DATA LOSS OF OUR MODEL: \", lasso_r.loss(lasso_r.predict(X_test), y_test))\n",
    "print(\"TEST DATA LOSS OF OUR SKLEARN's: \", lasso_r.loss(lasso_lm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Elastic Regression class of ours and Sklearns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA LOSS OF OUR MODEL:  [[281.43304329]]\n",
      "TEST DATA LOSS OF OUR SKLEARN's:  [[5090.2746201]]\n"
     ]
    }
   ],
   "source": [
    "# our method\n",
    "elastic_r = r.ElasticNetRegression(X_train, y_train, 0.0003, 0.0001)\n",
    "elastic_r.train(epochs=200, learning_rate=0.03)\n",
    "\n",
    "# sklearn's method\n",
    "elastic_lm = lm.ElasticNet(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print(\"TEST DATA LOSS OF OUR MODEL: \", elastic_r.loss(elastic_r.predict(X_test), y_test))\n",
    "print(\"TEST DATA LOSS OF OUR SKLEARN's: \", elastic_r.loss(elastic_lm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION TESTS WITH SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from Classification import MultClassLogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the performance of Multi class logistic Regression with that of sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris()['data'], load_iris()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_regressor = MultClassLogisticRegression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 50 loss: [[5.2875588]] acc: 0.7142857142857142\n",
      "After epoch 100 loss: [[3.01740481]] acc: 0.6964285714285714\n",
      "After epoch 150 loss: [[5.34806162]] acc: 0.6339285714285714\n",
      "After epoch 200 loss: [[2.7086825]] acc: 0.6964285714285714\n",
      "After epoch 250 loss: [[0.10451966]] acc: 0.9821428571428571\n",
      "After epoch 300 loss: [[0.10389937]] acc: 0.9821428571428571\n",
      "After epoch 350 loss: [[0.10337212]] acc: 0.9821428571428571\n",
      "After epoch 400 loss: [[0.10287525]] acc: 0.9821428571428571\n"
     ]
    }
   ],
   "source": [
    "my_regressor.fit(epochs=400, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(preds, gdt):\n",
    "    m = len(preds)\n",
    "    return 1/m * np.sum(preds == gdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "my_preds = my_regressor.predict(X_test)\n",
    "print(f\"My model: {acc(my_preds, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn: 0.9210526315789473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anindya/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# sklearn's model\n",
    "\n",
    "sk_regressor = LogisticRegression().fit(X_train, y_train)\n",
    "sk_preds = sk_regressor.predict(X_test)\n",
    "print(f\"Sklearn: {acc(sk_preds, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classifications tests of my model with that of sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=600, n_features=6, n_classes = 2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = MultClassLogisticRegression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 50 loss: [[0.99168921]] acc: 0.9422222222222222\n",
      "After epoch 100 loss: [[0.91034705]] acc: 0.9355555555555556\n",
      "After epoch 150 loss: [[1.04016077]] acc: 0.9311111111111111\n"
     ]
    }
   ],
   "source": [
    "reg.fit(epochs=150, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Classification import LogisticRegression as LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_b = LR(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 0 cost: 0.5780603485258072, acc: 0.6866666666666666\n",
      "After epoch 50 cost: 0.21569204001549458, acc: 0.9244444444444444\n",
      "After epoch 100 cost: 0.2157716401851269, acc: 0.9244444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anindya/Documents/ML from scratch/ML_from_scratch/Final_algorithms/Classification.py:143: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -1 / m * np.sum(self.y * np.log(Y_pred) + (1 - self.y) * (np.log(1 - Y_pred)))\n",
      "/home/anindya/Documents/ML from scratch/ML_from_scratch/Final_algorithms/Classification.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = -1 / m * np.sum(self.y * np.log(Y_pred) + (1 - self.y) * (np.log(1 - Y_pred)))\n"
     ]
    }
   ],
   "source": [
    "reg_b.train(learning_rate=0.03, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fef537ac494cdbbc31088862472f9b6fc2de5b0853fa06b655145b81d2845540"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
